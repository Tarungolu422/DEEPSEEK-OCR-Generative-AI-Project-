# -*- coding: utf-8 -*-
"""DEEPSEEK-OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w3YAClpdkMtumHthUkYd3zN_uqo4GTnI
"""

!nvidia-smi

# DeepSeek-OCR Implementation

# STEP 1: Install Required Dependencies
print("Step 1: Installing dependencies...")

# Uninstall existing transformers
!pip uninstall -y transformers -q

# Install exact versions from Hugging Face
!pip install -q torch==2.6.0 torchvision torchaudio
!pip install -q transformers==4.46.3
!pip install -q tokenizers==0.20.3
!pip install -q einops addict easydict
!pip install -q pillow accelerate sentencepiece protobuf

# Install flash-attention
!pip install flash-attn==2.7.3 --no-build-isolation -q

print("\n All dependencies installed successfully!")

import sys
from io import StringIO
import os
import tempfile
import shutil
import glob
import json
import torch
from transformers import AutoModel, AutoTokenizer
from PIL import Image
from google.colab import files
from IPython.display import display
import gradio as gr

print(" All imports loaded\n")



print("Step: Loading DeepSeek-OCR model...")
model_name = "deepseek-ai/DeepSeek-OCR"

try:
    # Load tokenizer
    print(f"Loading tokenizer from {model_name}...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True
    )

    # Load model
    print(f"Loading model from {model_name}...")
    model = AutoModel.from_pretrained(
        model_name,
        _attn_implementation='eager',
        trust_remote_code=True,
        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
        device_map="auto"
    )

    model = model.eval()
    print("\n Model loaded successfully!\n")

except Exception as e:
    print(f"\n Error loading model: {e}")


def perform_ocr(image, prompt="<image>\nExtract all text from the image.",
               base_size=1024, image_size=640, crop_mode=True):

    try:
        # Save image to temp file
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
            image.save(tmp.name)
            temp_image_path = tmp.name

        print(f"\n{'='*60}")
        print(f"Processing: {image.size} pixels")
        print(f"{'='*60}\n")

        temp_output = tempfile.mkdtemp()

        old_stdout = sys.stdout
        sys.stdout = captured = StringIO()

        try:
            # Run OCR
            model.infer(
                tokenizer=tokenizer,
                prompt=prompt,
                image_file=temp_image_path,
                output_path=temp_output,
                base_size=base_size,
                image_size=image_size,
                crop_mode=crop_mode,
                save_results=True,
                test_compress=False
            )
        finally:
            sys.stdout = old_stdout
            output_text = captured.getvalue()

        # Extract the actual content
        lines = output_text.split('\n')
        content = []
        collecting = False

        for line in lines:
            if 'SUMMARY' in line or 'SKILLS' in line or len(line) > 50:
                collecting = True

            if 'save results' in line.lower():
                break

            if collecting:
                if not any(x in line for x in ['torch.Size', 'BASE:', 'PATCHES:', '====', 'image:', 'other:']):
                    content.append(line)

        result = '\n'.join(content).strip()

        os.unlink(temp_image_path)
        shutil.rmtree(temp_output, ignore_errors=True)

        if result and len(result) > 20:
            print(f"\n{'='*60}")
            print(f" SUCCESS! Extracted {len(result)} characters")
            print(f"{'='*60}")
            print("\nPreview (first 400 chars):")
            print(result[:400] + "..." if len(result) > 400 else result[:400])
            print(f"\n{'='*60}\n")
            return result
        else:
            print(" No text extracted")
            return ""

    except Exception as e:
        import traceback
        error = f"Error: {e}\n{traceback.format_exc()}"
        print(error)
        return error

print(" perform_ocr() function ready\n")

    # GRADIO UI

def gradio_process_image(image):
    """Wrapper function for Gradio interface"""
    if image is None:
        return "Please upload an image.", None

    print("\nProcessing image via Gradio UI...")

    # Run OCR using the fixed perform_ocr function
    ocr_text = perform_ocr(image)

    # Save to a temporary file for download
    output_filename = "ocr_result.txt"
    with open(output_filename, "w", encoding="utf-8") as f:
        f.write(ocr_text)

    return ocr_text, output_filename

# Create Gradio Interface
print("\nLaunching Gradio UI...")
print("Click the public URL below to open the interface in a new tab.")

with gr.Blocks(title="DeepSeek-OCR Interface") as demo:
    gr.Markdown("# IntelliDoc OCR System")
    gr.Markdown("Upload an image to extract text using the DeepSeek-OCR model loaded in this Colab runtime.")

    with gr.Row():
        with gr.Column():
            input_image = gr.Image(type="pil", label="Upload Image")
            process_btn = gr.Button("Extract Text", variant="primary")

        with gr.Column():
            output_text = gr.Textbox(label="Extracted Text", show_copy_button=True, lines=20)
            download_file = gr.File(label="Download Result (.txt)")

    process_btn.click(
        fn=gradio_process_image,
        inputs=[input_image],
        outputs=[output_text, download_file]
    )

# Launch the interface
# share=True creates a public link accessible from anywhere
demo.launch(share=True, debug=True)

















# """
# SUCCESSFULLY TESTED
# DeepSeek-OCR Complete Code with Model Loading
# This script includes model initialization, fixed OCR extraction, and file saving.
# """

# import sys
# from io import StringIO
# import os
# import tempfile
# import shutil
# import glob
# import json
# import torch
# from transformers import AutoModel, AutoTokenizer
# from PIL import Image
# from google.colab import files
# from IPython.display import display

# print("‚úÖ All imports loaded\n")

# # ================================================================================
# # LOAD MODEL (DeepSeek-OCR)
# # ================================================================================

# print("Step: Loading DeepSeek-OCR model...")
# model_name = "deepseek-ai/DeepSeek-OCR"

# try:
#     # Load tokenizer
#     print(f"Loading tokenizer from {model_name}...")
#     tokenizer = AutoTokenizer.from_pretrained(
#         model_name,
#         trust_remote_code=True
#     )

#     # Load model
#     print(f"Loading model from {model_name}...")
#     model = AutoModel.from_pretrained(
#         model_name,
#         _attn_implementation='eager',
#         trust_remote_code=True,
#         torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
#         device_map="auto"
#     )

#     model = model.eval()
#     print("\n‚úÖ Model loaded successfully!\n")

# except Exception as e:
#     print(f"\n‚ùå Error loading model: {e}")
#     # Continue anyway in case model is already loaded in Colab memory

# # ================================================================================
# # FIXED OCR FUNCTION - Captures stdout from model
# # ================================================================================

# def perform_ocr(image, prompt="<image>\nExtract all text from the image.",
#                base_size=1024, image_size=640, crop_mode=True):
#     """
#     ‚úÖ FIXED: Captures the printed output from DeepSeek-OCR model
#     The model prints text to stdout but returns None - this captures it!
#     """
#     try:
#         # Save image to temp file
#         with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
#             image.save(tmp.name)
#             temp_image_path = tmp.name

#         print(f"\n{'='*60}")
#         print(f"Processing: {image.size} pixels")
#         print(f"{'='*60}\n")

#         temp_output = tempfile.mkdtemp()

#         # ‚úÖ KEY FIX: Capture what the model prints
#         old_stdout = sys.stdout
#         sys.stdout = captured = StringIO()

#         try:
#             # Run OCR
#             model.infer(
#                 tokenizer=tokenizer,
#                 prompt=prompt,
#                 image_file=temp_image_path,
#                 output_path=temp_output,
#                 base_size=base_size,
#                 image_size=image_size,
#                 crop_mode=crop_mode,
#                 save_results=True,
#                 test_compress=False
#             )
#         finally:
#             sys.stdout = old_stdout
#             output_text = captured.getvalue()

#         # Extract the actual content
#         lines = output_text.split('\n')
#         content = []
#         collecting = False

#         for line in lines:
#             # Start collecting after technical output
#             if 'SUMMARY' in line or 'SKILLS' in line or len(line) > 50:
#                 collecting = True
#             # Stop at save results marker
#             if 'save results' in line.lower():
#                 break

#             if collecting:
#                 # Skip technical lines
#                 if not any(x in line for x in ['torch.Size', 'BASE:', 'PATCHES:', '====', 'image:', 'other:']):
#                     content.append(line)

#         result = '\n'.join(content).strip()

#         # Cleanup
#         os.unlink(temp_image_path)
#         shutil.rmtree(temp_output, ignore_errors=True)

#         if result and len(result) > 20:
#             print(f"\n{'='*60}")
#             print(f"‚úÖ SUCCESS! Extracted {len(result)} characters")
#             print(f"{'='*60}")
#             print("\nPreview (first 400 chars):")
#             print(result[:400] + "..." if len(result) > 400 else result[:400])
#             print(f"\n{'='*60}\n")
#             return result
#         else:
#             print("‚ö†Ô∏è No text extracted")
#             return ""

#     except Exception as e:
#         import traceback
#         error = f"Error: {e}\n{traceback.format_exc()}"
#         print(error)
#         return error

# print("‚úÖ perform_ocr() function ready\n")

# # ================================================================================
# # UPLOAD AND PROCESS IMAGE
# # ================================================================================

# print("\n" + "="*60)
# print("üì§ UPLOAD YOUR IMAGE")
# print("="*60 + "\n")

# uploaded = files.upload()

# if uploaded:
#     filename = list(uploaded.keys())[0]
#     img = Image.open(filename)
#     print(f"\n‚úì Loaded: {filename}")
#     print(f"‚úì Size: {img.size} pixels\n")

#     # Display preview
#     display(img.reduce(4))

#     print("\n" + "="*60)
#     print("üîÑ RUNNING OCR...")
#     print("="*60)

#     # Run OCR
#     result = perform_ocr(img)

#     # Save result
#     if result and len(result) > 20 and not result.startswith("Error"):
#         output_file = "resume_ocr_output.txt"

#         with open(output_file, 'w', encoding='utf-8') as f:
#             f.write(result)

#         file_size = os.path.getsize(output_file)

#         print(f"\n{'='*60}")
#         print(f"‚úÖ‚úÖ FILE SAVED SUCCESSFULLY! ‚úÖ‚úÖ")
#         print(f"{'='*60}")
#         print(f"üìÑ Filename: {output_file}")
#         print(f"üìä Size: {file_size} bytes ({file_size/1024:.1f} KB)")
#         print(f"üìù Characters: {len(result)}")
#         print(f"üìã Lines: {len(result.splitlines())}")
#         print(f"{'='*60}\n")

#         print("üì• Downloading file to your computer...")
#         files.download(output_file)
#         print("‚úÖ Download triggered!\n")

#         print("\n" + "="*60)
#         print("üìÑ FULL EXTRACTED TEXT:")
#         print("="*60)
#         print(result)
#         print("="*60 + "\n")

#     else:
#         print("\n‚ùå No valid text to save")
#         if result:
#             print("Result preview:", result[:200])
# else:
#     print("No file uploaded.")
